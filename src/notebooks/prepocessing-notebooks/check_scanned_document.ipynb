{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from os.path import dirname, abspath\n",
    "from sklearn.decomposition import PCA\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções para listagem de docs no formato JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_opath(fd_path):\n",
    "    return abspath(dirname(fd_path.rstrip(\"/\")) + \"/../files_json\").rstrip(\"/\") + \"/\"\n",
    "\n",
    "def list_FD(fd):\n",
    "    fd = fd.rstrip(\"/\")\n",
    "    file_descriptor = [json.loads(line) for line in open(fd).readlines()]\n",
    "    files = [item[\"file_name\"] for item in file_descriptor if item[\"type\"] in [\"application/pdf\", \"pdf\", \"pdf;\"]]\n",
    "    return [f\"{dirname(fd)}/{f}\".rstrip(\";\") for f in files]\n",
    "\n",
    "def list_pdf(directory):\n",
    "    directory = directory.rstrip(\"/\")\n",
    "    file_d = glob.glob(f\"{directory}/data/files/file_description.jsonl\")\n",
    "    if len(file_d):\n",
    "        return [{\"docs\": list_FD(file_d[0]), \"output\": json_opath(file_d[0])}]\n",
    "             \n",
    "    multi_file_d = glob.glob(f\"{directory}/*/data/files/file_description.jsonl\")\n",
    "    if len(multi_file_d) == 0:\n",
    "        raise Error(\"No file descriptor\")\n",
    "             \n",
    "    file_descriptors = []\n",
    "    for file_d in multi_file_d:\n",
    "        file_descriptors.append({\"docs\": list_FD(file_d), \"output\": json_opath(file_d)})\n",
    "    return file_descriptors\n",
    "        \n",
    "def get_name(directory):\n",
    "    return re.search(\"licitacoes-(.*)/\", directory)[1].replace(\"-\", \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preenche um dict com o município e os arquivos json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_dir = glob.glob(\"../data/*licitacoes*/\")\n",
    "\n",
    "cities_docs = {}\n",
    "\n",
    "for city_dir in cities_dir:\n",
    "    city = get_name(city_dir)\n",
    "    if city == \"bh\":\n",
    "        continue\n",
    "    cities_docs[city] = list_pdf(city_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções para a dectção de docs escaneados\n",
    "\n",
    "> Boa parte dos documentos são detectados através dos campos de metadata.\n",
    "\n",
    "\n",
    "> Alguns documentos escaneados possuem um campo \"(cid:\\d+)\", porém eles já\\\n",
    ">foram detectados através dos metadados, portanto, não foram incluidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(doc):\n",
    "    metadata = doc[\"metadata\"]\n",
    "    has_author = int(\"Author\" in metadata)\n",
    "    word_creator = \"Creator\" in metadata and \"word\" in metadata[\"Creator\"].lower()\n",
    "    anycad_creator = \"Creator\" in metadata and \"cad\" in metadata[\"Creator\"].lower()\n",
    "    naps2_creator = \"Creator\" in metadata and \"naps2\" in metadata[\"Creator\"].lower()\n",
    "    ilovepdf = \"Producer\" in metadata and \"ilovepdf\" in metadata[\"Producer\"].lower()\n",
    "    return {\n",
    "        \"has_autor\": has_author,\n",
    "        \"word\": word_creator,\n",
    "        \"cad\": anycad_creator,\n",
    "        \"naps2\": naps2_creator,\n",
    "        \"ilovepdf\": ilovepdf\n",
    "    }\n",
    "\n",
    "def count_cid(doc):\n",
    "    n = 0\n",
    "    for page in doc['text_content']:\n",
    "        m = re.search(\"(\\(cid:\\d+\\))\", page)\n",
    "        if m:\n",
    "            return len(m.groups())\n",
    "    return 0\n",
    "\n",
    "def is_scanned(doc):\n",
    "    features = get_features(doc)\n",
    "    \n",
    "    return (not features[\"word\"] and features[\"cad\"]) or \\\n",
    "           (not features[\"word\"] and features[\"naps2\"]) or \\\n",
    "           (len(doc['text_content']) and doc['text_content'][0] == None and features[\"ilovepdf\"]) or \\\n",
    "           (doc['status'] == 'FAILED')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lista todos os prováveis documentos escaneados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    #                             DOC_ID       STATUS            MUNICIPIO\n",
      "--------------------------------------------------------------------------\n",
      "    1    79a70b2e386a7ae63c8435c2a41f12a6      SUCCESS               olaria\n",
      "    2    11a6281a3e73f0dc7ae77fb22fc00315      SUCCESS               olaria\n",
      "    3    a1feebf7fece41653a65ace04f9de6ad      SUCCESS               olaria\n",
      "    4    a7a6050bec5349fc6b5395839bac7e31      SUCCESS               olaria\n",
      "    5    65ca0c6888f52634fd63a1097d8dff9e      SUCCESS               olaria\n",
      "    6    2314b47af4b8d17443c5c6c2fc401024      SUCCESS               olaria\n",
      "    7    19a904b26613294dfa0e13a04730f5ef      SUCCESS               olaria\n",
      "    8    79a1c51973f2f1f52b9874d2615b287a      SUCCESS               olaria\n",
      "    9    950560a7461609a7df81cc37bed789b6      SUCCESS            coqueiral\n",
      "   10    2a034a7ff07d518edf2ec7bdb0290346      SUCCESS            coqueiral\n",
      "   11    ed6f00eef27e2e05f30c4f27208e541d      SUCCESS            coqueiral\n",
      "   12    871aeb7c6296988d87fde28a870997b1      SUCCESS            coqueiral\n",
      "   13    b0ca9b9b093f3259f69f749f73feb83b      SUCCESS            coqueiral\n",
      "   14    fb3d1448b221d51275833bef120a960b      SUCCESS            coqueiral\n",
      "   15    0ff05fc3cf3b0b8fe664b34749c5819a      SUCCESS            coqueiral\n",
      "   16    9495bcbbcf0619cce137874bb498a010      SUCCESS            coqueiral\n",
      "   17    4d65b3d0fb0cc3975cca51546d6a83b8      SUCCESS            coqueiral\n",
      "   18    19d9dbd2a54b20ff71da4fd46c4f3339      SUCCESS            coqueiral\n",
      "   19    9e31d4539639eb143bcbd4fe51ec32e5      SUCCESS            coqueiral\n",
      "   20    66609d162c9cf24cd755d3be2d39ab5b      SUCCESS            coqueiral\n",
      "   21    26936bb43033412e5f63cb67b43dba3e      SUCCESS            coqueiral\n",
      "   22    dbd99290d480a36fdcc434d086f70391      SUCCESS          pirapetinga\n",
      "   23    542a278287d8a399752bcfedd924ba5e      SUCCESS          pirapetinga\n",
      "   24    5553f727aa161926b7736565f808dfe0      SUCCESS          pirapetinga\n",
      "   25    9d8cb0b4ab4eae2a85e291387fe47433      SUCCESS          pirapetinga\n",
      "   26    4e2cab94764ce83ad87bb9d2a8bf05e3      SUCCESS          pirapetinga\n",
      "   27    61ba8cd62ce9d68ba40b12f6416b9fde      SUCCESS          pirapetinga\n",
      "   28    4c57c42e007e5cf4e6edf057668e15ec      SUCCESS          pirapetinga\n",
      "   29    a03f8ab5284d9c77a1984302611d9571      SUCCESS          pirapetinga\n",
      "   30    a19becff76c3d306a35fbf0ecb65c655      SUCCESS          pirapetinga\n",
      "   31    ada30a70f2bbc7b2d031d61596c305fd      SUCCESS          pirapetinga\n",
      "   32    ee119a9db89287f2b67274cc34edcaa7      SUCCESS          pirapetinga\n",
      "   33    c0d892563454aee00c8542244854b346      SUCCESS          pirapetinga\n",
      "   34    e9666b304a3ac80bb39fd57404ac233e      SUCCESS          pirapetinga\n",
      "   35    060f80783ccfe00d02a72b5392074f3c      SUCCESS          pirapetinga\n",
      "   36    2a06a8f9d4ac33708437c96353cb5274      SUCCESS          pirapetinga\n",
      "   37    8438b9a96099354fc63039bd040fbb5d      SUCCESS          pirapetinga\n",
      "   38    c90ac2668b6f7bf96d54fa92b8908f7f      SUCCESS          pirapetinga\n",
      "   39    01d01cf3503d3665b17f1916da262ce7      SUCCESS          pirapetinga\n",
      "   40    99816c024d7cfc7b476a8c8898a32887      SUCCESS          pirapetinga\n",
      "   41    687413b50e44062b9ae31373265a3b34      SUCCESS          pirapetinga\n",
      "   42    30eb0cad2144aa3e88cf846e49a9bcf5      SUCCESS          pirapetinga\n",
      "   43    2d0b66a94463bd83e6f68d33cf91d38a      SUCCESS          pirapetinga\n"
     ]
    }
   ],
   "source": [
    "header = f\"{'#':>5}{'DOC_ID':>35s} {'STATUS': >12} {'MUNICIPIO': >20}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "n = 0\n",
    "for city, documents_dirs in cities_docs.items():\n",
    "    for document_dir in documents_dirs:\n",
    "        base_path = document_dir[\"output\"]\n",
    "        docs = glob.glob(f\"{base_path}/*.json\")\n",
    "        for doc in docs:\n",
    "            with open(doc) as f:\n",
    "                doc_json = json.load(f)\n",
    "                c = count_cid(doc_json)                \n",
    "                if is_scanned(doc_json) and doc_json['status'] != 'FAILED':\n",
    "                    n += 1\n",
    "                    print(f\"{n:>5} {doc_json['file_id']:>35s} {doc_json['status']:>12} {city:>20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apenas funções para exploração (Apenas use para desenvolvimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets = pd.read_excel(\"../data/docs_escaneados/input/resultado_parcial.xlsx\", sheet_name=None)\n",
    "sheets = {k.lower():v for k,v in sheets.items() if \"doc_id\" in v.columns.str.lower()}\n",
    "for s in sheets.values():\n",
    "    s.columns = s.columns.str.lower()\n",
    "    if 'escaneado' not in s.columns:\n",
    "        s['escaneado'] = float('nan')\n",
    "    s.escaneado = s.escaneado.apply(lambda v: v == v) # Como NaN != NaN, v == v converte os escaneados para True e os não para False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_for = {}\n",
    "for f in glob.glob(\"../data/*/data/files/*.pdf\"):\n",
    "    doc_id = re.search(\"/([a-z0-9]+).pdf\", f)[1]\n",
    "    path_for[doc_id] = os.path.abspath(f)\n",
    "    \n",
    "for f in glob.glob(\"../data/*/*/data/files/*.pdf\"):\n",
    "    doc_id = re.search(\"/([a-z0-9]+).pdf\", f)[1]\n",
    "    path_for[doc_id] = os.path.abspath(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_for['2d0b66a94463bd83e6f68d33cf91d38a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
