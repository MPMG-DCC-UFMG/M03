{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/c24b93738bc036c1b66d0387555bf69a/hyperparameter_tuning_tutorial.ipynb#scrollTo=AJhAsV0FqHcc\n",
    "\n",
    "https://docs.ray.io/en/latest/tune/api_docs/schedulers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.stopper import ExperimentPlateauStopper\n",
    "import random\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import spacy\n",
    "import copy\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Fixa semente aleatória para garantir que os resultados possam ser reproduzidos\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "def tokenize (text, tok):\n",
    "    return [token.text for token in tok.tokenizer(text)]\n",
    "\n",
    "def encode_sentence(text, vocab2index, tok, N=1000):\n",
    "    tokenized = tokenize(text, tok)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class load_data(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Classe auxiliar para utilização do DataLoader\n",
    "    \"\"\"\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional LSTM running over word embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_matrix, word_embedding_dimension: int, hidden_dim: int, num_layers: int = 1, num_classes: int = 13, vocab_size: int = 0, dropout: float = 0, bidirectional: bool = True):\n",
    "        nn.Module.__init__(self)\n",
    "        self.config_keys = ['word_embedding_dimension', 'hidden_dim', 'num_layers', 'dropout', 'bidirectional']\n",
    "        self.word_embedding_dimension = word_embedding_dimension\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embeddings_dimension = hidden_dim\n",
    "        if self.bidirectional:\n",
    "            self.embeddings_dimension *= 2\n",
    "            \n",
    "        self.embeddings = nn.Embedding(vocab_size, word_embedding_dimension, padding_idx=0)\n",
    "        self.embeddings.weight=nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))\n",
    "        self.embeddings.weight.requires_grad=False\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.encoder = nn.LSTM(word_embedding_dimension, int(word_embedding_dimension/2), num_layers=num_layers, dropout=dropout, bidirectional=bidirectional, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(int(word_embedding_dimension/2), num_classes)\n",
    "\n",
    "    def forward(self, features, sentence_length):\n",
    "        x = self.embeddings(features)\n",
    "        x = self.dropout(x)\n",
    "        out_pack, (ht, ct) = self.encoder(x)\n",
    "        ht[-1] = self.dropout(ht[-1])\n",
    "        out = self.linear(ht[-1])\n",
    "        return out\n",
    "\n",
    "    \"\"\"def get_word_embedding_dimension(self) -> int:\n",
    "        return self.embeddings_dimension\n",
    "\n",
    "    def tokenize(self, text: str) -> List[int]:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def save(self, output_path: str):\n",
    "        with open(os.path.join(output_path, 'lstm_config.json'), 'w') as fOut:\n",
    "            json.dump(self.get_config_dict(), fOut, indent=2)\n",
    "\n",
    "        torch.save(self.state_dict(), os.path.join(output_path, 'pytorch_model.bin'))\n",
    "\n",
    "    def get_config_dict(self):\n",
    "        return {key: self.__dict__[key] for key in self.config_keys}\n",
    "\n",
    "    @staticmethod\n",
    "    def load(input_path: str):\n",
    "        with open(os.path.join(input_path, 'lstm_config.json'), 'r') as fIn:\n",
    "            config = json.load(fIn)\n",
    "\n",
    "        weights = torch.load(os.path.join(input_path, 'pytorch_model.bin'))\n",
    "        model = LSTM(**config)\n",
    "        model.load_state_dict(weights)\n",
    "        return model\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df_data, fold):\n",
    "    X = df_data.loc[df_data['fold'] == fold, 'four_pages_encoded'].values\n",
    "    y = df_data.loc[df_data['fold'] == fold, 'label_int'].values\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(df_data, config):\n",
    "    tok = spacy.load('pt_core_news_sm')\n",
    "\n",
    "    # count frequency of each word\n",
    "    \n",
    "    counts = Counter()\n",
    "    for index, row in df_data.loc[df_data['fold']==\"train\"].iterrows():\n",
    "        counts.update(tokenize(row['four_pages_processed'], tok))\n",
    "\n",
    "    #creating vocabulary\n",
    "    vocab2index = {\"\":0, \"UNK\":1}\n",
    "    words = [\"\", \"UNK\"]\n",
    "    for word in counts:\n",
    "        vocab2index[word] = len(words)\n",
    "        words.append(word)\n",
    "        \n",
    "    vocab_size = len(words)\n",
    "\n",
    "    # encoding\n",
    "    df_data['four_pages_encoded'] = None\n",
    "    df_data.loc[df_data['fold'] == 'train','four_pages_encoded'] = df_data.loc[df_data['fold'] == 'train','four_pages_processed'].apply(lambda x: np.array(encode_sentence(x,vocab2index, tok, config[\"num_terms\"] )))\n",
    "    df_data.loc[df_data['fold'] == 'val','four_pages_encoded'] = df_data.loc[df_data['fold'] == 'val','four_pages_processed'].apply(lambda x: np.array(encode_sentence(x,vocab2index, tok, config[\"num_terms\"] )))\n",
    "    df_data.loc[df_data['fold'] == 'test','four_pages_encoded'] = df_data.loc[df_data['fold'] == 'test','four_pages_processed'].apply(lambda x: np.array(encode_sentence(x,vocab2index, tok, config[\"num_terms\"] )))\n",
    "    \n",
    "    return df_data, vocab_size, vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return acc, f1_macro, f1_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(config, df_data):\n",
    "    # Split data\n",
    "    X_train, y_train = split_data(df_data, \"train\")\n",
    "    X_val, y_val = split_data(df_data, \"val\")\n",
    "    X_test, y_test = split_data(df_data, \"test\")\n",
    "    \n",
    "    # Load dataset\n",
    "    train_set = load_data(X_train, y_train)\n",
    "    val_set = load_data(X_val, y_val)\n",
    "    test_set = load_data(X_test, y_test)\n",
    "    \n",
    "    data_loaders = dict()\n",
    "\n",
    "    data_loaders[\"train\"] = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=8)\n",
    "    data_loaders[\"val\"] = torch.utils.data.DataLoader(\n",
    "        val_set,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=False,\n",
    "        num_workers=8)\n",
    "    data_loaders[\"test\"] = torch.utils.data.DataLoader(\n",
    "        test_set,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=False,\n",
    "        num_workers=8)\n",
    "    \n",
    "    return data_loaders\n",
    "\n",
    "def create_embedding_matrix(word_index,dimension, emb_model):    \n",
    "    emb_dir = \"/dados01/workspace/ufmg.f01dcc/m03/business_understanding/notebooks/lstm_data/embeddings/\"\n",
    "    if emb_model == \"wang2vec\":\n",
    "        df_emb = pd.read_csv(emb_dir+\"wang2vec_skip_s600.txt\", header=None, sep = \" \", index_col=0, skiprows=1)\n",
    "    elif emb_model == \"w2v_jur\":\n",
    "        df_emb = pd.read_csv(emb_dir+\"modelo_w2v_vec600_wd10_ct5_tec1.txt\", header=None, sep = \" \", index_col=0, skiprows=1)\n",
    "    elif emb_model == \"glove\":\n",
    "        df_emb = pd.read_csv(emb_dir+\"glove_s600.txt\", header=None, sep = \" \", index_col=0, skiprows=1)\n",
    "    elif emb_model == \"fastTex\":\n",
    "        df_emb = pd.read_csv(emb_dir+\"fasttext_skip_s600.txt\", header=None, sep = \" \", index_col=0, skiprows=1)\n",
    "        \n",
    "    df_emb = df_emb.loc[:, :600]\n",
    "        \n",
    "\n",
    "    embedding_dict = {key: val.values for key, val in df_emb.T.items()}\n",
    "    embedding_matrix=np.zeros((len(word_index)+1,dimension))\n",
    "\n",
    "    for word,index in word_index.items():\n",
    "        if word in embedding_dict:\n",
    "            embedding_matrix[index]=embedding_dict[word]\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, loader, fold=None, labels_dict = None, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    steps = 0\n",
    "    sum_loss = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            inputs, labels, sentence_length = data\n",
    "            inputs, labels = inputs.long().to(device), labels.long().to(device)\n",
    "            outputs = model(inputs, sentence_length)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            steps += 1\n",
    "            sum_loss += loss.cpu().detach().numpy()\n",
    "            \n",
    "            y_pred.extend(predicted.cpu().tolist())\n",
    "            y_true.extend(labels.cpu().tolist())\n",
    "    \n",
    "    metrics = [(sum_loss/steps)]\n",
    "    metrics.extend(calculate_metrics(y_true, y_pred))\n",
    "    #if fold:\n",
    "    #    plot_confusion_matrix(y_pred, y_true, fold, labels_dict)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config, checkpoint_dir=None, df_data=None):\n",
    "    df_data, vocab_size, vocab2index = encode_data(df_data, config)       \n",
    "    config.update({\n",
    "        \"num_classes\": df_data['label'].nunique(),\n",
    "        \"vocab_size\": vocab_size\n",
    "    })\n",
    "    \n",
    "    data_loaders = data_load(config, df_data)\n",
    "    embedding_matrix=create_embedding_matrix(vocab2index,dimension=600, emb_model=config[\"embeddings\"])\n",
    "    \n",
    "    train_loader = data_loaders[\"train\"]\n",
    "    val_loader = data_loaders[\"val\"]\n",
    "    \n",
    "    model = LSTM(\n",
    "        embedding_matrix = embedding_matrix,\n",
    "        word_embedding_dimension = config[\"embedding_dim\"], \n",
    "        hidden_dim = config[\"embedding_dim\"], \n",
    "        num_classes = config[\"num_classes\"], \n",
    "        vocab_size = config[\"vocab_size\"],\n",
    "        num_layers = config[\"num_layers\"], \n",
    "        dropout = config[\"dropout\"], \n",
    "        bidirectional = True\n",
    "    )\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "    model.to(device)\n",
    "    \n",
    "    best_model = copy.deepcopy(model)\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    \"\"\"if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\"\"\"\n",
    "\n",
    "    for epoch in range(150):  # loop over the dataset multiple times\n",
    "        model.train()\n",
    "        training_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels, sentence_length = data\n",
    "            inputs, labels = inputs.long().to(device), labels.long().to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs, sentence_length)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            epoch_steps += 1\n",
    "            training_loss += loss.cpu().detach().numpy()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            y_pred.extend(predicted.cpu().tolist())\n",
    "            y_true.extend(labels.cpu().tolist())\n",
    "            \n",
    "        train_metrics = [(training_loss/epoch_steps)]\n",
    "        train_metrics.extend(calculate_metrics(y_true, y_pred))\n",
    "\n",
    "        val_metrics = eval_model(model, val_loader, device=device)\n",
    "        \n",
    "        if val_metrics[0] < best_loss:\n",
    "            best_loss = val_metrics[0]\n",
    "            with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "                path = os.path.join(checkpoint_dir, \"model.pth\")\n",
    "                torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
    "        elif val_metrics[0] == np.nan:\n",
    "            val_metrics[0] = 10\n",
    "        tune.report(loss=val_metrics[0], accuracy=val_metrics[1], F1_Macro=val_metrics[2], F1_Weighted=val_metrics[3])\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 15:24:08,149\tWARNING experiment.py:303 -- No name detected on trainable. Using DEFAULT.\n",
      "2021-09-21 15:24:08,151\tINFO registry.py:67 -- Detected unknown callable for trainable. Converting to class.\n",
      "2021-09-21 15:24:18,683\tWARNING worker.py:1228 -- Warning: The actor ImplicitFunc is very large (72 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
      "\u001b[2m\u001b[36m(pid=26335)\u001b[0m /dados01/workspace/ufmg.f01dcc/py37/lib/python3.7/site-packages/ray/workers/default_worker.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "\u001b[2m\u001b[36m(pid=26335)\u001b[0m   \"--node-ip-address\",\n",
      "\u001b[2m\u001b[36m(pid=26335)\u001b[0m /dados01/workspace/ufmg.f01dcc/py37/lib/python3.7/site-packages/ray/workers/default_worker.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "\u001b[2m\u001b[36m(pid=26335)\u001b[0m   required=True,\n",
      "\u001b[2m\u001b[36m(pid=26335)\u001b[0m /dados01/workspace/ufmg.f01dcc/py37/lib/python3.7/site-packages/ray/workers/default_worker.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "\u001b[2m\u001b[36m(pid=26335)\u001b[0m   type=str,\n",
      "\u001b[2m\u001b[36m(pid=26335)\u001b[0m /dados01/workspace/ufmg.f01dcc/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "\u001b[2m\u001b[36m(pid=26335)\u001b[0m   \"num_layers={}\".format(dropout, num_layers))\n",
      "2021-09-21 15:26:03,384\tWARNING util.py:166 -- The `start_trial` operation took 0.614 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:26:23,549\tWARNING util.py:166 -- The `start_trial` operation took 0.558 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:26:44,715\tWARNING util.py:166 -- The `start_trial` operation took 0.556 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:26:45,739\tWARNING util.py:166 -- The `start_trial` operation took 0.522 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:27:06,909\tWARNING util.py:166 -- The `start_trial` operation took 0.564 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:27:44,549\tWARNING util.py:166 -- The `start_trial` operation took 0.536 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:28:22,614\tWARNING util.py:166 -- The `start_trial` operation took 0.564 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:28:23,121\tWARNING util.py:166 -- The `process_trial_save` operation took 0.504 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:28:23,626\tWARNING util.py:166 -- The `start_trial` operation took 0.503 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:28:43,962\tWARNING util.py:166 -- The `start_trial` operation took 0.582 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:29:03,991\tWARNING util.py:166 -- The `start_trial` operation took 0.597 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:29:44,194\tWARNING util.py:166 -- The `start_trial` operation took 0.578 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:30:05,236\tWARNING util.py:166 -- The `start_trial` operation took 0.595 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:30:23,632\tWARNING util.py:166 -- The `start_trial` operation took 0.574 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:32:02,467\tWARNING util.py:166 -- The `start_trial` operation took 0.667 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:32:22,004\tWARNING util.py:166 -- The `start_trial` operation took 0.609 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:33:00,491\tWARNING util.py:166 -- The `start_trial` operation took 0.535 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:33:38,258\tWARNING util.py:166 -- The `start_trial` operation took 0.586 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:34:36,140\tWARNING util.py:166 -- The `start_trial` operation took 0.548 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:34:54,624\tWARNING util.py:166 -- The `start_trial` operation took 0.532 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:35:32,133\tWARNING util.py:166 -- The `start_trial` operation took 0.527 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:35:51,871\tWARNING util.py:166 -- The `start_trial` operation took 0.580 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:36:12,730\tWARNING util.py:166 -- The `start_trial` operation took 0.592 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:36:51,490\tWARNING util.py:166 -- The `start_trial` operation took 0.583 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:37:30,931\tWARNING util.py:166 -- The `start_trial` operation took 0.574 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:38:09,168\tWARNING util.py:166 -- The `start_trial` operation took 0.657 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:39:06,806\tWARNING util.py:166 -- The `start_trial` operation took 0.588 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:39:27,630\tWARNING util.py:166 -- The `start_trial` operation took 0.581 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:39:47,239\tWARNING util.py:166 -- The `start_trial` operation took 0.574 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:40:44,078\tWARNING util.py:166 -- The `start_trial` operation took 0.586 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:41:24,885\tWARNING util.py:166 -- The `start_trial` operation took 0.579 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:41:45,815\tWARNING util.py:166 -- The `start_trial` operation took 0.575 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:42:07,141\tWARNING util.py:166 -- The `start_trial` operation took 0.580 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:42:47,535\tWARNING util.py:166 -- The `start_trial` operation took 0.576 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:43:07,135\tWARNING util.py:166 -- The `start_trial` operation took 0.673 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:43:44,825\tWARNING util.py:166 -- The `start_trial` operation took 0.569 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:44:05,452\tWARNING util.py:166 -- The `start_trial` operation took 0.578 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:44:25,249\tWARNING util.py:166 -- The `start_trial` operation took 0.584 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:44:45,102\tWARNING util.py:166 -- The `start_trial` operation took 0.641 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:45:05,261\tWARNING util.py:166 -- The `start_trial` operation took 0.591 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:45:25,297\tWARNING util.py:166 -- The `start_trial` operation took 0.590 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:46:05,946\tWARNING util.py:166 -- The `start_trial` operation took 0.564 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:46:44,852\tWARNING util.py:166 -- The `start_trial` operation took 0.532 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:49:17,247\tWARNING util.py:166 -- The `start_trial` operation took 0.573 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:49:56,331\tWARNING util.py:166 -- The `start_trial` operation took 0.541 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:50:14,922\tWARNING util.py:166 -- The `start_trial` operation took 0.518 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:50:35,385\tWARNING util.py:166 -- The `start_trial` operation took 0.567 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:51:35,562\tWARNING util.py:166 -- The `start_trial` operation took 0.645 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 15:51:55,294\tWARNING util.py:166 -- The `start_trial` operation took 0.605 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:52:32,205\tWARNING util.py:166 -- The `start_trial` operation took 0.565 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:52:50,751\tWARNING util.py:166 -- The `start_trial` operation took 0.577 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:53:11,423\tWARNING util.py:166 -- The `start_trial` operation took 0.505 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:53:50,639\tWARNING util.py:166 -- The `start_trial` operation took 0.573 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:54:10,662\tWARNING util.py:166 -- The `start_trial` operation took 0.575 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:54:48,514\tWARNING util.py:166 -- The `start_trial` operation took 0.568 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:55:08,298\tWARNING util.py:166 -- The `start_trial` operation took 0.587 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:55:27,928\tWARNING util.py:166 -- The `start_trial` operation took 0.658 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:55:46,455\tWARNING util.py:166 -- The `start_trial` operation took 0.538 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:56:05,732\tWARNING util.py:166 -- The `start_trial` operation took 0.544 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:56:25,601\tWARNING util.py:166 -- The `start_trial` operation took 0.531 s, which may be a performance bottleneck.\n",
      "2021-09-21 15:57:21,871\tWARNING util.py:166 -- The `start_trial` operation took 0.629 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=26333)\u001b[0m /dados01/workspace/ufmg.f01dcc/py37/lib/python3.7/site-packages/ray/workers/default_worker.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "\u001b[2m\u001b[36m(pid=26333)\u001b[0m   \"--node-ip-address\",\n",
      "\u001b[2m\u001b[36m(pid=26333)\u001b[0m /dados01/workspace/ufmg.f01dcc/py37/lib/python3.7/site-packages/ray/workers/default_worker.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "\u001b[2m\u001b[36m(pid=26333)\u001b[0m   required=True,\n",
      "\u001b[2m\u001b[36m(pid=26333)\u001b[0m /dados01/workspace/ufmg.f01dcc/py37/lib/python3.7/site-packages/ray/workers/default_worker.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "\u001b[2m\u001b[36m(pid=26333)\u001b[0m   type=str,\n",
      "2021-09-21 15:59:24,887\tWARNING util.py:166 -- The `start_trial` operation took 0.562 s, which may be a performance bottleneck.\n",
      "2021-09-21 16:00:16,610\tWARNING util.py:166 -- The `start_trial` operation took 0.506 s, which may be a performance bottleneck.\n",
      "2021-09-21 16:01:07,236\tWARNING util.py:166 -- The `start_trial` operation took 0.547 s, which may be a performance bottleneck.\n",
      "2021-09-21 16:04:33,656\tWARNING util.py:166 -- The `start_trial` operation took 0.520 s, which may be a performance bottleneck.\n",
      "2021-09-21 16:06:17,540\tWARNING util.py:166 -- The `start_trial` operation took 0.526 s, which may be a performance bottleneck.\n",
      "2021-09-21 16:07:09,496\tWARNING util.py:166 -- The `start_trial` operation took 0.526 s, which may be a performance bottleneck.\n",
      "2021-09-21 16:08:52,298\tWARNING util.py:166 -- The `start_trial` operation took 0.585 s, which may be a performance bottleneck.\n",
      "2021-09-21 16:10:36,289\tWARNING util.py:166 -- The `start_trial` operation took 0.613 s, which may be a performance bottleneck.\n",
      "2021-09-21 16:11:27,716\tWARNING util.py:166 -- The `start_trial` operation took 0.544 s, which may be a performance bottleneck.\n",
      "2021-09-21 16:14:01,344\tWARNING util.py:166 -- The `start_trial` operation took 0.526 s, which may be a performance bottleneck.\n",
      "2021-09-21 16:14:52,578\tWARNING util.py:166 -- The `start_trial` operation took 0.572 s, which may be a performance bottleneck.\n",
      "2021-09-21 16:23:27,395\tWARNING util.py:166 -- The `start_trial` operation took 0.635 s, which may be a performance bottleneck.\n"
     ]
    }
   ],
   "source": [
    "def main(num_samples=10, max_num_epochs=10):\n",
    "    set_seed(SEED)\n",
    "    df_data = pd.read_csv(\"./lstm_data/preprocessed_data_v2_2.csv\")\n",
    "\n",
    "    #load_data(df_data)\n",
    "    config = {\n",
    "        \"embedding_dim\": tune.choice([600]),\n",
    "        \"hidden_dim\": tune.choice([150, 300]),\n",
    "        \"dropout\": tune.choice([0.2, 0.5]),\n",
    "        \"lr\": tune.choice([0.00001, 0.00005]),\n",
    "        \"num_terms\": tune.choice([300, 500, 1000]),\n",
    "        \"batch_size\": tune.choice([24, 72]),\n",
    "        \"embeddings\": tune.choice([\"w2v_jur\", \"glove\", \"fastTex\"]),\n",
    "        \"num_layers\": tune.choice([1, 3]),\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=50,\n",
    "        reduction_factor=2)\n",
    "    reporter = CLIReporter(\n",
    "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"F1_Macro\", \"F1_Weighted\", \"training_iteration\"])\n",
    "\n",
    "    result = tune.run(\n",
    "        partial(train_model, checkpoint_dir=\"./lstm_data/models/\", df_data=df_data),\n",
    "        resources_per_trial={\"cpu\": 0, \"gpu\": 1},\n",
    "        stop=ExperimentPlateauStopper(metric=\"loss\", mode='min', patience=10),\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter,\n",
    "        keep_checkpoints_num=1,\n",
    "        checkpoint_score_attr=\"loss\",\n",
    "        verbose = 0\n",
    "    )\n",
    "\n",
    "    \"\"\"best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Val:\\\\n loss %.3f, accuracy %.3f, F1-Macro %.3f, F1-Weighted %.3f, \" % (\n",
    "        best_trial.last_result[\"loss\"], best_trial.last_result[\"accuracy\"], best_trial.last_result[\"F1_Macro\"], best_trial.last_result[\"F1_Weighted\"]))\n",
    "\n",
    "    df_data, vocab_size = encode_data(df_data, best_trial.config)\n",
    "    num_classes = df_data['label'].nunique()\n",
    "    best_trained_model = LSTM_fixed_len(vocab_size, best_trial.config[\"embedding_dim\"], best_trial.config[\"embedding_dim\"], num_classes, best_trial.config[\"dropout\"])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    try:\n",
    "        model_state, optimizer_state = torch.load(os.path.join(\n",
    "            best_checkpoint_dir, \"checkpoint\"))\n",
    "        best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "        test_metrics = test_accuracy(best_trained_model, df_data, device)\n",
    "        print(\"Test:\\\\n loss %.3f, accuracy %.3f, F1-Macro %.3f, F1-Weighted %.3f, \" % (test_metrics[0], test_metrics[1], test_metrics[2], test_metrics[3]))\n",
    "    except:\n",
    "        print(\"Model not saved, BAD LOSS\")\"\"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the number of GPUs per trial here:\n",
    "    main(num_samples=250, max_num_epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
